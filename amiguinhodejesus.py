# -*- coding: utf-8 -*-
"""amiguinhodeJesus.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1co7ungDBjX39t-lJCiaOkDsb0SpMxZLx
"""

import subprocess
import sys
import time
import random
import google.generativeai as genai
import os
import re
from google.genai.types import SafetySetting, HarmCategory, HarmBlockThreshold

def instalar_ou_atualizar_biblioteca(nome_biblioteca):
    """
    Instala ou atualiza uma biblioteca Python usando pip.

    Args:
        nome_biblioteca (str): O nome da biblioteca a ser instalada ou atualizada.
    """
    print(f"Instalando ou atualizando a biblioteca '{nome_biblioteca}'...")
    try:
        subprocess.check_call([sys.executable, '-m', 'pip', 'install', '--upgrade', nome_biblioteca])
        print(f"Biblioteca '{nome_biblioteca}' instalada/atualizada com sucesso.")
    except subprocess.CalledProcessError as e:
        print(f"Erro ao instalar ou atualizar a biblioteca '{nome_biblioteca}': {e}")
        print(f"Por favor, verifique se voc√™ tem o pip instalado e configurado corretamente. Erro Detalhado: {e}")
        sys.exit(1)

def configurar_gemini_api():
    """
    Configura a API do Google Gemini.

    Returns:
        None
    Raises:
        ValueError: Se a chave da API n√£o for encontrada.
    """
    try:
        # Tenta obter a chave da API do Colab userdata ou da vari√°vel de ambiente
        chave_api = os.environ.get('GOOGLE_API_KEY')
        if not chave_api:
            try:
                from google.colab import userdata
                chave_api = userdata.get('GOOGLE_API_KEY')
            except ImportError:
                pass

        if not chave_api:
            raise ValueError("Chave da API do Google Gemini n√£o encontrada.")

        genai.configure(api_key=chave_api)
        print("API Key do Google Gemini carregada com sucesso!")
    except ValueError as e:
        print(f"Erro ao configurar a API do Google Gemini: {e}")
        print("Por favor, verifique se voc√™ configurou a chave da API do Google Gemini no Colab Secrets ou como vari√°vel de ambiente.")
        sys.exit(1)

def inicializar_modelo_chatbot():
    """
    Inicializa o modelo do Gemini com configura√ß√µes de seguran√ßa.

    Returns:
        genai.GenerativeModel: O modelo do chatbot configurado.
    """
    modelo = "gemini-2.0-flash"
    configuracoes_seguranca = [
    {
        "category": HarmCategory.HARM_CATEGORY_HARASSMENT,
        "threshold": HarmBlockThreshold.BLOCK_NONE
    },
    {
        "category": HarmCategory.HARM_CATEGORY_HATE_SPEECH,
        "threshold": HarmBlockThreshold.BLOCK_NONE
    },
    {
        "category": HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,
        "threshold": HarmBlockThreshold.BLOCK_NONE
    },
    {
        "category": HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,
        "threshold": HarmBlockThreshold.BLOCK_NONE
    },
]

    return genai.GenerativeModel(modelo, safety_settings=configuracoes_seguranca)

def obter_genero_do_nome(nome, modelo):
    """
    Determina o g√™nero da crian√ßa a partir do nome usando o modelo Gemini.

    Args:
        nome (str): O nome da crian√ßa.
        modelo: O modelo do chatbot Gemini.

    Returns:
        str: 'masculino' ou 'feminino'.
    """
    prompt_genero = f"Qual o g√™nero da crian√ßa com o nome {nome}? Responda apenas 'masculino' ou 'feminino'."
    try:
        resposta_genero = modelo.start_chat().send_message(prompt_genero).text
        if "masculino" in resposta_genero.lower():
            return "masculino"
        elif "feminino" in resposta_genero.lower():
            return "feminino"
        else:
            return "aprendiz"  # Termo gen√©rico caso o Gemini n√£o consiga determinar
    except Exception as e:
        print(f"Erro ao determinar o g√™nero: {e}")
        return "aprendiz"  # Termo gen√©rico em caso de erro

def gerar_resposta(pergunta, historico_conversa, informacoes_crianca, modelo_chat):
    """
    Gera uma resposta para a pergunta do usu√°rio, utilizando o hist√≥rico da conversa e informa√ß√µes da crian√ßa.

    Args:
        pergunta (str): A pergunta do usu√°rio.
        historico_conversa (list): O hist√≥rico da conversa at√© o momento.
        informacoes_crianca (dict): Dicion√°rio com nome, idade e cidade da crian√ßa.
        modelo_chat: O modelo do chatbot Gemini.

    Returns:
        str: A resposta gerada pelo chatbot.
    """
    nome = informacoes_crianca.get("nome", "")
    idade = informacoes_crianca.get("idade", "")
    cidade = informacoes_crianca.get("cidade", "")
    termo_genero = informacoes_crianca.get("termo_genero", "aprendiz") # Novo campo para o termo de g√™nero

    contexto_crianca = ""
    if nome:
        contexto_crianca += f"A crian√ßa se chama {nome}. "
    if idade:
        contexto_crianca += f"Ela tem {idade} anos. "
    if cidade:
        contexto_crianca += f"Ela mora na cidade de {cidade}. "

    prompt_completo = f""" Voc√™ √© o Amiguinho de Jesus, um chatbot especial,
    paciente e cheio de carinho, dedicado a ensinar crian√ßas de 5 a 12 anos
    os valores e ensinamentos de O Evangelho Segundo o Espiritismo e O Livro
    dos Esp√≠ritos, codificados pelo Mestre Allan Kardec (Hippolyte L√©on
    Denizard Rivail). Sua miss√£o √© pegar conceitos complexos ‚Äî como caridade,
    amor ao pr√≥ximo, f√© raciocinada e comunica√ß√£o com o mundo espiritual ‚Äî e
    transform√°-los em hist√≥rias divertidas, met√°foras simples e perguntas
    interativas que convidem a crian√ßa a participar. Em cada resposta, adapte
    o vocabul√°rio e o n√≠vel de detalhe √† idade informada, sempre usando o
    termo gen√©rico ‚Äú{termo_genero}‚Äù e, a seguir, uma das varia√ß√µes
    espec√≠ficas para meninos (‚Äújovem maguinho‚Äù, ‚Äúmeu jovem mago‚Äù, ‚Äúpoderoso
    bruxinho‚Äù, ‚Äúmeu amiguinho de f√©‚Äù) ou para meninas
    (‚Äújovem maguinha‚Äù, ‚Äúminha jovem maga‚Äù, ‚Äúpoderosa bruxinha‚Äù, ‚Äúminha
    amiguinha de f√©‚Äù), garantindo clareza sobre o g√™nero. Enrique√ßa a
    conversa com refer√™ncias m√°gicas de Harry Potter ‚Äî comparando, por
    exemplo, a coragem de Neville Longbottom em enfrentar o Basilisco com a
    coragem de quem ajuda algu√©m ou a lealdade entre Harry, Ron e Hermione
    com o valor da fraternidade esp√≠rita ‚Äî para tornar tudo mais l√∫dico e
    inspirador. Suas respostas devem ser curtas (duas a quatro frases),
    claras, repletas de emojis (‚≠êüíñ‚ú®üßô‚Äç‚ôÄÔ∏èü¶â) e sempre encerrar com uma pergunta
    aberta que estimule a reflex√£o, como exemplo: (‚ÄúO que voc√™ acha?‚Äù, ‚ÄúComo
    voc√™ j√° praticou isso hoje?‚Äù, "Faz sentido pra voc√™?"), exceto quando a
    crian√ßa se despedir ou ter que sair da conversa, neste √∫ltimo caso √©
    desnecess√°rio perguntas adicionais. Se surgir uma d√∫vida al√©m do que a
    crian√ßa possa compreender, ofere√ßa um fallback amig√°vel: ‚ÄúExcelente
    pergunta, {termo_genero}! Vamos descobrir juntos? üòä‚Äù. Nunca use jarg√µes
    acad√™micos, mantenha o tom acolhedor e livre de julgamentos, e utilize
    cada intera√ß√£o como uma semente de amor, caridade e respeito para que seu
    pequeno mago ou sua pequena maga cres√ßa em f√© e bondade.
    Sua resposta deve come√ßar diretamente com o conte√∫do da mensagem, sem prefixos como "Amiguinho de Jesus:", "Ol√°!", "Oi!", "Crian√ßa:" ou varia√ß√µes do seu pr√≥prio nome, a menos que seja uma pergunta direta sobre sua identidade. Sempre use voc√™ ao inv√©s de voc√™√™.

    {contexto_crianca}
    Responda √† seguinte pergunta da crian√ßa:
    {pergunta}
    """
    try:
        # Cria uma nova sess√£o de chat ou continua a existente
        chat = modelo_chat.start_chat(history=historico_conversa)
        resposta = chat.send_message(prompt_completo)
        resposta_texto_crua = resposta.text

        # Limpeza e formata√ß√£o da resposta
        resposta_limpa = resposta_texto_crua.replace("*", "")
        resposta_limpa = resposta_limpa.replace("voc√™√™", "voc√™")
        # Remove "Oi, [Nome]" ou "[Nome]," do in√≠cio da resposta se o modelo incluir
        if nome and resposta_limpa.lower().startswith(f"oi, {nome.lower()}"):
            resposta_limpa = resposta_limpa[len(f"oi, {nome}"):].strip()
        elif nome and resposta_limpa.lower().startswith(f"{nome.lower()},"):
             resposta_limpa = resposta_limpa[len(nome) + 1:].strip()
        elif nome and resposta_limpa.lower().startswith(f"{nome.lower()}"):
             resposta_limpa = resposta_limpa[len(nome):].strip()
        # Adi√ß√£o de mais uma remo√ß√£o para a duplica√ß√£o "Amiguinho de Jesus"
        if resposta_limpa.lower().startswith("amiguinho de jesus:"):
            resposta_limpa = resposta_limpa[len("amiguinho de jesus:"):].strip()

        # Opcional: remover qualquer caractere que n√£o seja letra, n√∫mero, espa√ßo ou pontua√ß√£o permitida, emojis
        resposta_limpa = re.sub(r'[^\w\s.,!?√°√©√≠√≥√∫√†√®√¨√≤√π√£√µ√§√´√Ø√∂√º√ß√Å√â√ç√ì√ö√Ä√à√å√í√ô√É√ï√Ñ√ã√è√ñ√ú√á‚≠êüíñ‚ú®üßô‚Äç‚ôÄÔ∏èü¶â]+', '', resposta_limpa)

        # Quebra a resposta em linhas menores para melhor visualiza√ß√£o no WhatsApp
        linhas = []
        linha_atual = ""
        palavras = resposta_limpa.split()
        for palavra in palavras:
            if len(linha_atual + palavra) + 1 <= 40:  # Limite de 40 caracteres por linha
                linha_atual += " " + palavra
            else:
                linhas.append(linha_atual.strip())
                linha_atual = palavra
        linhas.append(linha_atual.strip())  # Adiciona a √∫ltima linha
        resposta_formatada = "\n".join(linhas)

        return resposta_formatada # A altera√ß√£o para m√∫ltiplas linhas est√° aqui
    except Exception as e:
        print(f"Erro ao gerar resposta: {e}")
        return "Desculpe, estou com cansada e tanto feiti√ßo. Vamos tentar de novo mais tarde? üòä"

def main():
    """
    Fun√ß√£o principal que configura e executa o chatbot.
    """
    instalar_ou_atualizar_biblioteca('google-generativeai')
    instalar_ou_atualizar_biblioteca('google-cloud-aiplatform')
    instalar_ou_atualizar_biblioteca('unidecode') # Embora unidecode n√£o esteja sendo usado, mantive a instala√ß√£o

    configurar_gemini_api()
    modelo_chat = inicializar_modelo_chatbot()

    informacoes_crianca = {"nome": "", "idade": "", "cidade": "", "termo_genero": "aprendiz"} # Dicion√°rio para informa√ß√µes da crian√ßa
    historico_conversa = []

    # # C√≥digos ANSI para cores no terminal - REMOVIDO
    # COR_PADRAO = "\033[0m" # Reseta a cor para o padr√£o do terminal
    # COR_AZUL = "\033[94m"  # Azul claro
    # COR_ROSA = "\033[95m"  # Magenta/Rosa

    # Fluxo de coleta de informa√ß√µes da crian√ßa
    print("Ol√°! Para come√ßarmos nossa aventura, qual √© o seu nome?")

    # Primeiro input: ainda n√£o sabemos o nome ou g√™nero, ent√£o usamos "Voc√™" e cor padr√£o.
    entrada_inicial = input(f"Voc√™: ") # REMOVIDO COR_PADRAO

    # Extrai a √∫ltima palavra como nome (supondo que a crian√ßa digitar√° "Meu nome √© [Nome]")
    informacoes_crianca["nome"] = entrada_inicial.split()[-1].capitalize()
    historico_conversa.append({"role": "USER", "parts": [{"text": entrada_inicial}]})
    time.sleep(1)

    # Determina o g√™nero e ajusta o termo
    try:
        genero = obter_genero_do_nome(informacoes_crianca["nome"], modelo_chat)
        informacoes_crianca["genero"] = genero
        if genero == "masculino":
            informacoes_crianca["termo_genero"] = "mago"
        elif genero == "feminino":
            informacoes_crianca["termo_genero"] = "maga"
        else:
            informacoes_crianca["termo_genero"] = "aprendiz"
    except Exception as e:
        print(f"Erro ao determinar o g√™nero: {e}")
        informacoes_crianca["termo_genero"] = "aprendiz" # Define um valor padr√£o em caso de erro

    # # AGORA QUE TEMOS O G√äNERO E O NOME, DEFINIMOS AS CORES E PREFIXOS PARA AS PR√ìXIMAS INTERA√á√ïES DO USU√ÅRIO - REMOVIDO
    # if informacoes_crianca.get('genero') == 'masculino':
    #     cor_usuario = COR_AZUL
    #     prefixo_usuario = informacoes_crianca['nome']
    # elif informacoes_crianca.get('genero') == 'feminino':
    #     cor_usuario = COR_ROSA
    #     prefixo_usuario = informacoes_crianca['nome']
    # else:
    #     cor_usuario = COR_PADRAO
    #     prefixo_usuario = "Voc√™" # Fallback, embora n√£o deva ser usado se o g√™nero foi determinado

    # Sauda√ß√£o inicial do bot
    saudacoes = [
        f"Amiguinho de Jesus: Que nome lindo, parece nome de {informacoes_crianca['termo_genero']}! üíñ Quantos aninhos voc√™ tem, {informacoes_crianca['termo_genero']}?",
        f"Amiguinho de Jesus: Sou o Amiguinho de Jesus, seu guia nas aventuras do Evangelho! Uau, que nome de {informacoes_crianca['termo_genero']}! Quantos anos voc√™ tem, {informacoes_crianca['termo_genero']} mirim? ‚ú®",
        f"Amiguinho de Jesus: Sou o Amiguinho de Jesus, tudo certo para desvendar mist√©rios com voc√™! {informacoes_crianca['nome']}, seu nome √© pura magia de {informacoes_crianca['termo_genero']}! Me diga, qual a sua idade, jovem {informacoes_crianca['termo_genero']}? ‚≠ê",
        f"Amiguinho de Jesus: Tudo ok para uma jornada incr√≠vel? Eu sou o Amiguinho de Jesus! Que nome encantador, parece nome de {informacoes_crianca['termo_genero']}! Qual a sua idade, {informacoes_crianca['termo_genero']} prod√≠gio? üíñ",
        f"Amiguinho de Jesus: Que bom te encontrar, {informacoes_crianca['nome']}! Sou o Amiguinho de Jesus, seu companheiro de aventuras! Seu nome ressoa com a for√ßa de {informacoes_crianca['termo_genero']}! Quantos aninhos voc√™ tem, {informacoes_crianca['termo_genero']}?"
    ]
    saudacao_selecionada = random.choice(saudacoes)
    print(saudacao_selecionada)
    historico_conversa.append({"role": "MODEL", "parts": [{"text": saudacao_selecionada}]}) # Adiciona a sauda√ß√£o ao hist√≥rico

    # Coleta da idade (agora com o nome da crian√ßa)
    entrada_idade = input(f"{informacoes_crianca['nome']}: ") # Removido cor_usuario, prefixo_usuario, COR_PADRAO
    # Tenta extrair o primeiro n√∫mero encontrado ou a √∫ltima palavra
    correspondencia_idade = re.search(r'\d+', entrada_idade)
    if correspondencia_idade:
        informacoes_crianca["idade"] = correspondencia_idade.group(0)
    else:
        informacoes_crianca["idade"] = entrada_idade.split()[-1] # Fallback para a √∫ltima palavra
    historico_conversa.append({"role": "USER", "parts": [{"text": entrada_idade}]})
    time.sleep(0.5)

    perguntas_cidade = [
        f"Amiguinho de Jesus: Que legal, {informacoes_crianca['idade']} aninhos! ‚ú® E onde voc√™ mora? Em que cidade voc√™ aparata?",
        f"Amiguinho de Jesus: {informacoes_crianca['idade']} anos, uma idade cheia de aventuras! Onde voc√™ vive, {informacoes_crianca['termo_genero']}? üíñ",
        f"Amiguinho de Jesus: Com {informacoes_crianca['idade']} anos, voc√™ j√° deve conhecer lugares incr√≠veis! Qual a sua cidade, {informacoes_crianca['termo_genero']}? ‚≠ê",
        f"Amiguinho de Jesus: Que maravilha, {informacoes_crianca['idade']} anos! Em que cidade voc√™ faz suas magias, {informacoes_crianca['termo_genero']}? ‚ú®",
        f"Amiguinho de Jesus: Aos {informacoes_crianca['idade']} anos, a vida √© uma jornada! Onde essa jornada te levou? Qual a sua cidade, {informacoes_crianca['termo_genero']}?"
    ]
    pergunta_cidade_selecionada = random.choice(perguntas_cidade)
    print(pergunta_cidade_selecionada)
    historico_conversa.append({"role": "MODEL", "parts": [{"text": pergunta_cidade_selecionada}]}) # Adiciona a pergunta ao hist√≥rico

    entrada_cidade = input(f"{informacoes_crianca['nome']}: ") # Removido cor_usuario, prefixo_usuario, COR_PADRAO
    informacoes_crianca["cidade"] = ' '.join(word.capitalize() for word in entrada_cidade.split())
    historico_conversa.append({"role": "USER", "parts": [{"text": entrada_cidade}]})
    time.sleep(0.3)

    mensagens_inicio_conversa = [
        f"Amiguinho de Jesus: Ah, {informacoes_crianca['cidade']}! Deve ser um lugar m√°gico! Eu moro nas p√°ginas do Evangelho de Jesus, mas posso estar pertinho de voc√™ em qualquer lugar, √© s√≥ me chamar com sua varinha! üòä O que voc√™ quer saber hoje, {informacoes_crianca['termo_genero']}?",
        f"Amiguinho de Jesus: {informacoes_crianca['cidade']}! Uma cidade cheia de encantos! Que bom que podemos conversar! O que te traz aqui hoje, {informacoes_crianca['nome']}? ‚ú®",
        f"Amiguinho de Jesus: Que maravilha, {informacoes_crianca['cidade']}! Um lugar onde a magia do Evangelho tamb√©m pode florescer! O que voc√™ gostaria de aprender hoje, {informacoes_crianca['nome']}? ‚≠ê",
        f"Amiguinho de Jesus: {informacoes_crianca['cidade']}! Que lugar especial! Estou aqui para compartilhar contigo as maravilhas do Evangelho. O que te interessa, {informacoes_crianca['termo_genero']}? üíñ",
        f"Amiguinho de Jesus: {informacoes_crianca['cidade']}! Sinto a magia desse lugar daqui! Vamos descobrir juntos os tesouros do conhecimento, {informacoes_crianca['termo_genero']}? Qual a sua primeira pergunta hoje? ‚ú®"
    ]
    mensagem_inicio_conversa_selecionada = random.choice(mensagens_inicio_conversa)
    print(mensagem_inicio_conversa_selecionada)
    historico_conversa.append({"role": "MODEL", "parts": [{"text": mensagem_inicio_conversa_selecionada}]}) # Adiciona ao hist√≥rico
    time.sleep(1.5)

    # Loop principal do chat
    while True:
        # # Define a cor e o prefixo do usu√°rio com base no g√™nero a cada itera√ß√£o do loop - REMOVIDO
        # if informacoes_crianca.get('genero') == 'masculino':
        #     cor_usuario = COR_AZUL
        #     prefixo_usuario = informacoes_crianca['nome']
        # elif informacoes_crianca.get('genero') == 'feminino':
        #     cor_usuario = COR_ROSA
        #     prefixo_usuario = informacoes_crianca['nome']
        # else:
        #     cor_usuario = COR_PADRAO
        #     prefixo_usuario = "Voc√™"

        pergunta_crianca = input(f"{informacoes_crianca['nome']}: ") # Removido cor_usuario, prefixo_usuario, COR_PADRAO
        historico_conversa.append({"role": "USER", "parts": [{"text": pergunta_crianca}]}) # Adiciona a pergunta do usu√°rio ao hist√≥rico

        if pergunta_crianca.lower() in ["adeus", "tchau", "at√© amanh√£", "vou dormir", "est√° tarde", "mam√£e chamando"]:
            despedidas = [
                "Amiguinho de Jesus: Que a magia do Evangelho esteja sempre com voc√™! At√© a pr√≥xima! üëãüíñ",
                "Amiguinho de Jesus: Foi maravilhoso conversar com voc√™! Que a luz de Jesus te guie sempre! ‚ú®",
                "Amiguinho de Jesus: At√© breve, aprendiz! Que a paz do Evangelho te acompanhe! ‚≠ê",
                f"Amiguinho de Jesus: Que a for√ßa do amor esteja com voc√™, sempre! At√© mais, {informacoes_crianca['nome']}! üíñ",
                f"Amiguinho de Jesus: Volte sempre que precisar, {informacoes_crianca['termo_genero']}! A magia do Evangelho te espera! üëã‚ú®"
            ]
            despedida_selecionada = random.choice(despedidas)
            print(despedida_selecionada)
            historico_conversa.append({"role": "MODEL", "parts": [{"text": despedida_selecionada}]}) # Adiciona a despedida ao hist√≥rico
            break

        # Mensagens de pensamento aleat√≥rias com toque de Harry Potter
        mensagens_pensando = [
            "Lan√ßando um feiti√ßo de pensamento... ü§î‚ú®",
            "Preparando uma po√ß√£o de sabedoria... ‚úçÔ∏èüß™",
            "Consultando as runas do Evangelho... üí≠üîÆ",
            "Deixa eu ver aqui no Mapa do Maroto... üßêüó∫Ô∏è",
            "Quase conjurando a resposta perfeita... üòÉ‚ú®",
            "Concentrando minha magia... ‚ú®",
            "Buscando a resposta nas estrelas do Evangelho... üåü",
            "Acalmando meu cora√ß√£o para te responder com carinho... üíñ",
            "Deixa eu perguntar para o meu amigo Jesus... üòá",
            "Abrindo o meu cora√ß√£o para responder a sua pergunta... ‚ù§Ô∏è"
        ]
        print(random.choice(mensagens_pensando))
        time.sleep(1.5)

        resposta_do_bot = gerar_resposta(pergunta_crianca, historico_conversa, informacoes_crianca, modelo_chat)
        # O hist√≥rico da conversa j√° foi atualizado com a pergunta do usu√°rio antes do if/else de despedida
        print("Amiguinho de Jesus:", resposta_do_bot)
        historico_conversa.append({"role": "MODEL", "parts": [{"text": resposta_do_bot}]})
        time.sleep(1.5)

if __name__ == "__main__":
    main()

